{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from config import my_models, my_scoring\n",
    "## for data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import ppscore as pps\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as impipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, r2_score, fbeta_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import  StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#  the MLFLOW libs from GPT 3.5\n",
    "# import numpy as np\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop('id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI: <br>\n",
    "Body mass index is a value derived from the `mass` and `height` of a person.<br> The BMI is defined as the body mass divided by the square of the body height.. since we don't have those values, we can predict them eaither using ML or just filling with Median/Mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the imputer in the pipeline down in the  code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =raw_data['stroke'].value_counts(sort = True).index\n",
    "sizes = raw_data['stroke'].value_counts(sort = True)\n",
    "\n",
    "colors = [\"lightblue\",\"red\"]\n",
    "explode = (0.05,0) \n",
    " \n",
    "plt.figure(figsize=(3,3))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n",
    "\n",
    "plt.title('Number of stroke in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(col, bins=30, title=\"\",xlabel=\"\",ax=None):\n",
    "    sns.distplot(col, bins=bins,ax=ax)\n",
    "    ax.set_title(f'Histogram of {title}',fontsize=20)\n",
    "    ax.set_xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(11,7),constrained_layout=True)\n",
    "plot_hist(raw_data.bmi,title='Bmi',xlabel=\"Level of the BMI\",ax=axes[0])\n",
    "\n",
    "plot_hist(raw_data.age,bins=30,title='Age',xlabel='Age',ax=axes[1])\n",
    "\n",
    "plot_hist(raw_data.avg_glucose_level,title='Serum Creatinine', xlabel='Level of serum creatinine in the blood (mg/dL)', ax=axes[2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y=\"smoking_status\", hue=\"stroke\", kind=\"count\",\n",
    "            palette=\"pastel\", edgecolor=\".6\",\n",
    "            data=raw_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems that the stroke is **`not highly`** corralated to smokers since the proportion of person having a stroke is fairly the same among the other smoking status."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Power Score (PPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pps.matrix(raw_data)\n",
    "mat = mat[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "ax = sns.heatmap(mat, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5)\n",
    "ax.set_title(\"PPS matrix\")\n",
    "ax.set_xlabel(\"feature\")\n",
    "ax.set_ylabel(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "sns.catplot(x=\"gender\", y=\"stroke\", hue=\"heart_disease\", kind=\"bar\", data=raw_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in terms of gender it's not truly spreatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"gender\", y=\"stroke\", hue=\"Residence_type\", kind=\"bar\", data=raw_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sounds like Males in Urban are just a bit more likly to have strok than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`hypertension`* : it's already between 0 and 1, doesn't need scalling<br>\n",
    "*`heart_disease`* : it's a binary value: 0-> don't have, 1-> have<br>\n",
    "*`strok`* : also binary vlaues\n",
    "*`avg_glucose_level`* : need scalling !<br>\n",
    "*`bmi`* : need too<br>\n",
    "*`age`* : i'd like to binning it, i will try it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Splitting` the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = raw_data.loc[:,:'smoking_status']\n",
    "target = raw_data.loc[:,'stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = target\n",
    "print(\"X.shape: {}  y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature preprocessing and pipline:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n",
    "cat_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer(strategy= 'most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown= 'ignore', sparse= False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', KNNImputer(n_neighbors= 5)),\n",
    "        ('sclaer', StandardScaler() ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, resample=False):\n",
    "    \n",
    "    if resample:\n",
    "        clf = impipeline(steps=[('preprocessor', preprocessor ),\n",
    "                ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "                ('classifier', classifier)])\n",
    "\n",
    "    else: \n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor ),\n",
    "                      ('classifier', classifier)])\n",
    "        \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_model(model, y_true, y_predicted):\n",
    "    print(\"R-squared scores are:\\n\")\n",
    "    print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_true, y_predicted)))\n",
    "    \n",
    "    # print('score (training): {:.3f}'\n",
    "    #  .format(model.score(x1, y1)))\n",
    "    # print('score (test): {:.3f}'\n",
    "    #     .format(model.score(x2, y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = my_models\n",
    "scoring = my_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5  \n",
    "preprocessing_step_v0 = preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Track all the models using MLflow\n",
    "for model_name, model_params in models.items():\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_param(\"preprocessing\", \"preprocessing_step_v0\")\n",
    "        \n",
    "        # Define the pipeline with the preprocessing steps and classifier\n",
    "        pipeline = impipeline([\n",
    "            # edite the preprocessing\n",
    "            ('preprocessing', preprocessing_step_v0),\n",
    "            ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "            ('classifier', model_params[\"estimator\"])\n",
    "        ])\n",
    "        \n",
    "        # Define the hyperparameter grid to search over\n",
    "        param_grid = model_params[\"param_grid\"]\n",
    "        \n",
    "        # Define the grid search object\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=cv, scoring=scoring, refit=\"auc\", n_jobs=-1)\n",
    "        \n",
    "        # Fit the grid search object to the data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best estimator from the grid search\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "\n",
    "        # Step 5: Use a couple of matrices such as AUC, accuracy, precision, recall, F1, F2\n",
    "        y_pred_train = best_estimator.predict(X_train)\n",
    "        y_proba_train = best_estimator.predict_proba(X_train)[:, 1] # Probability of positive class\n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "        precision_train = precision_score(y_train, y_pred_train)\n",
    "        recall_train = recall_score(y_train, y_pred_train)\n",
    "        f1_train = f1_score(y_train, y_pred_train)\n",
    "        auc_train = roc_auc_score(y_train, y_proba_train)\n",
    "        f2_train = make_scorer(fbeta_score, beta=2)(best_estimator, X_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred_test = best_estimator.predict(X_test)\n",
    "        y_proba_test = best_estimator.predict_proba(X_test)[:, 1] # Probability of positive class\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        precision_test = precision_score(y_test, y_pred_test)\n",
    "        recall_test = recall_score(y_test, y_pred_test)\n",
    "        f1_test = f1_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_proba_test)\n",
    "        f2_test = make_scorer(fbeta_score, beta=2)(best_estimator, X_test, y_test)\n",
    "        \n",
    "        \n",
    "        # Step 6: Plot all matrices\n",
    "        mlflow.log_metric(\"accuracy_train\", accuracy_train)\n",
    "        mlflow.log_metric(\"precision_train\", precision_train)\n",
    "        mlflow.log_metric(\"recall_train\", recall_train)\n",
    "        mlflow.log_metric(\"f1_score_train\", f1_train)\n",
    "        mlflow.log_metric(\"auc_train\", auc_train)\n",
    "        mlflow.log_metric(\"f2_score_train\", f2_train)\n",
    "        mlflow.log_metric(\"accuracy_test\", accuracy_test)\n",
    "        mlflow.log_metric(\"precision_test\", precision_test)\n",
    "        mlflow.log_metric(\"recall_test\", recall_test)\n",
    "        mlflow.log_metric(\"f1_score_test\", f1_test)\n",
    "        mlflow.log_metric(\"auc_test\", auc_test)\n",
    "        mlflow.log_metric(\"f2_score_test\", f2_test)\n",
    "        \n",
    "        \n",
    "        # Log the best hyperparameters\n",
    "        mlflow.log_params(grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
